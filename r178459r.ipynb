{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNhYTVWiDXrNgd3is89LuQt"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"FPEez_BAJXMo"},"outputs":[],"source":["import operator\n","import random\n","import time\n","from functools import cmp_to_key\n","from tqdm import tqdm\n","\n","from algorithms.basic_mondrian.models.numrange import NumRange\n","from algorithms.basic_mondrian.utils.utility import (cmp_str, get_num_list_from_str,\n","                                          qid_to_key)\n","\n","__DEBUG = False\n","# att_tree store root node for each att\n","ATT_TREES = []\n","# databack store all record for dataset\n","LEN_DATA = 0\n","QI_LEN = 0\n","QI_RANGE = []\n","IS_CAT = []\n","# get_LCA, gen_result and NCP require huge running time, while most of the function are duplicate\n","# we can use cache to reduce the running time\n","LCA_CACHE = []\n","NCP_CACHE = {}\n","\n","\n","class Cluster(object):\n","\n","    \"\"\"Cluster is for cluster based k-anonymity\n","    self.member: record list in cluster\n","    self.gen_result: generlized value for one cluster\n","    \"\"\"\n","\n","    def __init__(self, member, gen_result, information_loss=0.0):\n","        self.information_loss = information_loss\n","        self.member = member\n","        self.gen_result = gen_result[:]\n","        self.center = gen_result[:]\n","        for i in range(QI_LEN):\n","            if IS_CAT[i] is False:\n","                self.center[i] = str(sum([float(t[i]) for t in self.member]) * 1.0 / len(self.member))\n","\n","    def add_record(self, record):\n","        \"\"\"\n","        add record to cluster\n","        \"\"\"\n","        self.member.append(record)\n","        self.update_gen_result(record, record)\n","\n","    def update_cluster(self):\n","        \"\"\"update cluster information when member is changed\n","        \"\"\"\n","        self.gen_result = cluster_generalization(self.member)\n","        for i in range(QI_LEN):\n","            if IS_CAT[i]:\n","                self.center[i] = self.gen_result[i]\n","            else:\n","                self.center[i] = str(sum([float(t[i]) for t in self.member]) * 1.0 / len(self.member))\n","        self.information_loss = len(self.member) * NCP(self.gen_result)\n","\n","    def update_gen_result(self, merge_gen_result, center, num=1):\n","        \"\"\"\n","        update gen_result and information_loss after adding record or merging cluster\n","        :param merge_gen_result:\n","        :return:\n","        \"\"\"\n","        self.gen_result = generalization(self.gen_result, merge_gen_result)\n","        current_len = len(self.member)\n","        for i in range(QI_LEN):\n","            if IS_CAT[i]:\n","                self.center[i] = self.gen_result[i]\n","            else:\n","                self.center[i] = str((float(self.center[i]) * (current_len - num) +\n","                                      float(center[i]) * num) / current_len)\n","        self.information_loss = len(self.member) * NCP(self.gen_result)\n","\n","    def add_same_record(self, record):\n","        \"\"\"\n","        add record with same qid to cluster\n","        \"\"\"\n","        self.member.append(record)\n","\n","    def merge_cluster(self, cluster):\n","        \"\"\"merge cluster into self and do not delete cluster elements.\n","        update self.gen_result\n","        \"\"\"\n","        self.member.extend(cluster.member)\n","        self.update_gen_result(cluster.gen_result, cluster.center, len(cluster))\n","\n","    def __getitem__(self, item):\n","        \"\"\"\n","        :param item: index number\n","        :return: gen_result[item]\n","        \"\"\"\n","        return self.gen_result[item]\n","\n","    def __len__(self):\n","        \"\"\"\n","        return number of records in cluster\n","        \"\"\"\n","        return len(self.member)\n","\n","    def __str__(self):\n","        return str(self.gen_result)\n","\n","\n","def r_distance(source, target):\n","    \"\"\"\n","    Return distance between source (cluster or record)\n","    and target (cluster or record). The distance is based on\n","    NCP (Normalized Certainty Penalty) on relational part.\n","    If source or target are cluster, func need to multiply\n","    source_len (or target_len).\n","    \"\"\"\n","    source_gen = source\n","    target_gen = target\n","    source_len = 1\n","    target_len = 1\n","    # check if target is Cluster\n","    if isinstance(target, Cluster):\n","        target_gen = target.gen_result\n","        target_len = len(target)\n","    # check if souce is Cluster\n","    if isinstance(source, Cluster):\n","        source_gen = source.gen_result\n","        source_len = len(source)\n","    if source_gen == target_gen:\n","        return 0\n","    gen = generalization(source_gen, target_gen)\n","    # len should be taken into account\n","    distance = (source_len + target_len) * NCP(gen)\n","    return distance\n","\n","\n","def diff_distance(record, cluster):\n","    \"\"\"\n","    Return IL(cluster and record) - IL(cluster).\n","    \"\"\"\n","    gen_after = generalization(record, cluster.gen_result)\n","    return NCP(gen_after) * (len(cluster) + 1) - cluster.information_loss\n","\n","\n","def NCP(record):\n","    \"\"\"Compute NCP (Normalized Certainty Penalty)\n","    when generate record to gen_result.\n","    \"\"\"\n","    ncp = 0.0\n","    # exclude SA values(last one type [])\n","    list_key = qid_to_key(record)\n","    try:\n","        return NCP_CACHE[list_key]\n","    except KeyError:\n","        pass\n","    for i in range(QI_LEN):\n","        # if leaf_num of numerator is 1, then NCP is 0\n","        width = 0.0\n","        if IS_CAT[i] is False:\n","            try:\n","                float(record[i])\n","            except ValueError:\n","                temp = record[i].split(',')\n","                width = float(temp[1]) - float(temp[0])\n","        else:\n","            width = len(ATT_TREES[i][record[i]]) * 1.0\n","        width /= QI_RANGE[i]\n","        ncp += width\n","    NCP_CACHE[list_key] = ncp\n","    return ncp\n","\n","\n","def get_LCA(index, item1, item2):\n","    \"\"\"Get lowest commmon ancestor (including themselves)\"\"\"\n","    # get parent list from\n","    if item1 == item2:\n","        return item1\n","    try:\n","        return LCA_CACHE[index][item1 + item2]\n","    except KeyError:\n","        pass\n","    parent1 = ATT_TREES[index][item1].parent[:]\n","    parent2 = ATT_TREES[index][item2].parent[:]\n","    parent1.insert(0, ATT_TREES[index][item1])\n","    parent2.insert(0, ATT_TREES[index][item2])\n","    min_len = min(len(parent1), len(parent2))\n","    last_LCA = parent1[-1]\n","    # note here: when trying to access list reversely, take care of -0\n","    for i in range(1, min_len + 1):\n","        if parent1[-i].value == parent2[-i].value:\n","            last_LCA = parent1[-i]\n","        else:\n","            break\n","    LCA_CACHE[index][item1 + item2] = last_LCA.value\n","    return last_LCA.value\n","\n","\n","def generalization(record1, record2):\n","    \"\"\"\n","    Compute relational generalization result of record1 and record2\n","    \"\"\"\n","    gen = []\n","    for i in range(QI_LEN):\n","        if IS_CAT[i] is False:\n","            split_number = []\n","            split_number.extend(get_num_list_from_str(record1[i]))\n","            split_number.extend(get_num_list_from_str(record2[i]))\n","            split_number = list(set(split_number))\n","            if len(split_number) == 1:\n","                gen.append(split_number[0])\n","            else:\n","                split_number.sort(key=cmp_to_key(cmp_str))\n","                gen.append(split_number[0] + ',' + split_number[-1])\n","        else:\n","            gen.append(get_LCA(i, record1[i], record2[i]))\n","    return gen\n","\n","\n","def cluster_generalization(records):\n","    \"\"\"\n","    calculat gen_result of records(list) recursively.\n","    Compute both relational gen_result for records (list).\n","    \"\"\"\n","    len_r = len(records)\n","    gen = records[0]\n","    for i in range(1, len_r):\n","        gen = generalization(gen, records[i])\n","    return gen\n","\n","\n","def find_best_knn(index, k, data):\n","    \"\"\"key fuction of KNN. Find k nearest neighbors of record, remove them from data\"\"\"\n","    dist_dict = {}\n","    record = data[index]\n","    # add random seed to cluster\n","    for i, t in enumerate(data):\n","        if i == index:\n","            continue\n","        dist = r_distance(record, t)\n","        dist_dict[i] = dist\n","    sorted_dict = sorted(dist_dict.items(), key=operator.itemgetter(1))\n","    knn = sorted_dict[:k - 1]\n","    knn.append((index, 0))\n","    record_index = [t[0] for t in knn]\n","    elements = [data[t[0]] for t in knn]\n","    gen = cluster_generalization(elements)\n","    cluster = Cluster(elements, gen, k * NCP(gen))\n","    # delete multiple elements from data according to knn index list\n","    return cluster, record_index\n","\n","\n","def find_best_cluster_iloss(record, clusters):\n","    \"\"\"residual assignment. Find best cluster for record.\"\"\"\n","    min_distance = 1000000000000\n","    min_index = 0\n","    best_cluster = clusters[0]\n","    for i, t in enumerate(clusters):\n","        distance = r_distance(record, t.gen_result)\n","        if distance < min_distance:\n","            min_distance = distance\n","            min_index = i\n","            best_cluster = t\n","    # add record to best cluster\n","    return min_index\n","\n","\n","def find_best_cluster_iloss_increase(record, clusters):\n","    \"\"\"residual assignment. Find best cluster for record.\"\"\"\n","    min_diff = 1000000000000\n","    min_index = 0\n","    best_cluster = clusters[0]\n","    for i, t in enumerate(clusters):\n","        IF_diff = diff_distance(record, t)\n","        if IF_diff < min_diff:\n","            min_distance = IF_diff\n","            min_index = i\n","            best_cluster = t\n","    # add record to best cluster\n","    return min_index\n","\n","\n","def find_furthest_record(record, data):\n","    \"\"\"\n","    :param record: the latest record be added to cluster\n","    :param data: remain records in data\n","    :return: the index of the furthest record from r_index\n","    \"\"\"\n","    max_distance = 0\n","    max_index = -1\n","    for index in range(len(data)):\n","        current_distance = r_distance(record, data[index])\n","        if current_distance >= max_distance:\n","            max_distance = current_distance\n","            max_index = index\n","    return max_index\n","\n","\n","def find_best_record_iloss_increase(cluster, data):\n","    \"\"\"\n","    :param cluster: current\n","    :param data: remain dataset\n","    :return: index of record with min diff on information loss\n","    \"\"\"\n","    min_diff = 1000000000000\n","    min_index = 0\n","    for index, record in enumerate(data):\n","        # IL(cluster and record) and |cluster| + 1 is a constant\n","        # so IL(record, cluster.gen_result) is enough\n","        IF_diff = diff_distance(record, cluster)\n","        if IF_diff < min_diff:\n","            min_diff = IF_diff\n","            min_index = index\n","    return min_index\n","\n","\n","def clustering_knn(data, k=25):\n","    \"\"\"\n","    Group record according to QID distance. KNN\n","    \"\"\"\n","    clusters = []\n","    # randomly choose seed and find k-1 nearest records to form cluster with size k\n","    while len(data) >= k:\n","        index = random.randrange(len(data))\n","        cluster, record_index = find_best_knn(index, k, data)\n","        data = [t for i, t in enumerate(data[:]) if i not in set(record_index)]\n","        clusters.append(cluster)\n","    # residual assignment\n","    while len(data) > 0:\n","        t = data.pop()\n","        cluster_index = find_best_cluster_iloss(t, clusters)\n","        clusters[cluster_index].add_record(t)\n","    return clusters\n","\n","\n","def clustering_kmember(data, k=25):\n","    \"\"\"\n","    Group record according to NCP. K-member\n","    \"\"\"\n","    clusters = []\n","    # randomly choose seed and find k-1 nearest records to form cluster with size k\n","    r_pos = random.randrange(len(data))\n","    r_i = data[r_pos]\n","    while len(data) >= k:\n","        r_pos = find_furthest_record(r_i, data)\n","        r_i = data.pop(r_pos)\n","        cluster = Cluster([r_i], r_i)\n","        while len(cluster) < k:\n","            r_pos = find_best_record_iloss_increase(cluster, data)\n","            r_j = data.pop(r_pos)\n","            cluster.add_record(r_j)\n","        clusters.append(cluster)\n","    # residual assignment\n","    while len(data) > 0:\n","        t = data.pop()\n","        cluster_index = find_best_cluster_iloss_increase(t, clusters)\n","        clusters[cluster_index].add_record(t)\n","    return clusters\n","\n","\n","def adjust_cluster(cluster, residual, k):\n","    center = cluster.center\n","    dist_dict = {}\n","    # add random seed to cluster\n","    for i, t in enumerate(cluster.member):\n","        dist = r_distance(center, t)\n","        dist_dict[i] = dist\n","    sorted_dict = sorted(dist_dict.iteritems(), key=operator.itemgetter(1))\n","    need_adjust_index = [t[0] for t in sorted_dict[k:]]\n","    need_adjust = [cluster.member[t] for t in need_adjust_index]\n","    residual.extend(need_adjust)\n","    # update cluster\n","    cluster.member = [t for i, t in enumerate(cluster.member)\n","                      if i not in set(need_adjust_index)]\n","    cluster.update_cluster()\n","\n","\n","def clustering_oka(data, k=25):\n","    \"\"\"\n","    Group record according to NCP. OKA: one time pass k-means\n","    \"\"\"\n","    clusters = []\n","    can_clusters = []\n","    less_clusters = []\n","    # randomly choose seed and find k-1 nearest records to form cluster with size k\n","    seed_index = random.sample(range(len(data)), len(data) / k)\n","    for index in seed_index:\n","        record = data[index]\n","        can_clusters.append(Cluster([record], record))\n","    data = [t for i, t in enumerate(data[:]) if i not in set(seed_index)]\n","    while len(data) > 0:\n","        record = data.pop()\n","        index = find_best_cluster_iloss(record, can_clusters)\n","        can_clusters[index].add_record(record)\n","    residual = []\n","    for cluster in can_clusters:\n","        if len(cluster) < k:\n","            less_clusters.append(cluster)\n","        else:\n","            if len(cluster) > k:\n","                adjust_cluster(cluster, residual, k)\n","            clusters.append(cluster)\n","    while len(residual) > 0:\n","        record = residual.pop()\n","        if len(less_clusters) > 0:\n","            index = find_best_cluster_iloss(record, less_clusters)\n","            less_clusters[index].add_record(record)\n","            if less_clusters[index] >= k:\n","                clusters.append(less_clusters.pop(index))\n","        else:\n","            index = find_best_cluster_iloss(record, clusters)\n","            clusters[index].add_record(record)\n","    return clusters\n","\n","\n","def init(att_trees, data, SA_num, QI_num=-1):\n","    \"\"\"\n","    init global variables\n","    \"\"\"\n","    global ATT_TREES, DATA_BACKUP, LEN_DATA, QI_RANGE, IS_CAT, QI_LEN, LCA_CACHE, NCP_CACHE, SA_INDEX\n","    SA_INDEX = SA_num\n","    ATT_TREES = att_trees\n","    QI_RANGE = []\n","    IS_CAT = []\n","    LEN_DATA = len(data)\n","    LCA_CACHE = []\n","    NCP_CACHE = {}\n","    if QI_num <= 0:\n","        QI_LEN = len(data[0]) - 1\n","    else:\n","        QI_LEN = QI_num\n","    for i in range(QI_LEN):\n","        LCA_CACHE.append(dict())\n","        if isinstance(ATT_TREES[i], NumRange):\n","            IS_CAT.append(False)\n","            QI_RANGE.append(ATT_TREES[i].range)\n","        else:\n","            IS_CAT.append(True)\n","            QI_RANGE.append(len(ATT_TREES[i]['*']))\n","\n","\n","def clustering_based_k_anon(att_trees, data, k, QI_num, SA_num, type_alg):\n","    \"\"\"\n","    the main function of clustering based k-anon\n","    \"\"\"\n","    init(att_trees, data, SA_num, QI_num)\n","    result = []\n","    start_time = time.time()\n","    if type_alg == 'knn':\n","        print(\"Begin to KNN Cluster based on NCP\")\n","        clusters = clustering_knn(data, k)\n","    elif type_alg == 'kmember':\n","        print(\"Begin to K-Member Cluster based on NCP\")\n","        clusters = clustering_kmember(data, k)\n","    elif type_alg == 'oka':\n","        print(\"Begin to OKA Cluster based on NCP\")\n","        clusters = clustering_oka(data, k)\n","    else:\n","        print(\"Please choose merge algorithm types\")\n","        print(\"knn | kmember\")\n","        return (0, (0, 0))\n","    rtime = float(time.time() - start_time)\n","    for cluster in tqdm(clusters):\n","        final_result = []\n","        for i in range(len(cluster)):\n","            # Custom! For non QI Values\n","            tmp = []\n","            for s in range(len(cluster.member[i]) - len(SA_INDEX), len(cluster.member[i])):\n","                tmp += [cluster.member[i][s]]\n","            final_result.append(cluster.gen_result + tmp)\n","        result.extend(final_result)\n","\n","    return (result, rtime)"]}]}